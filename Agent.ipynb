{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# Step 1: Install lightweight dependencies\n",
        "# =====================================\n",
        "!pip install gTTS openai-whisper phonikud\n",
        "\n",
        "# =====================================\n",
        "# Step 2: Imports\n",
        "# =====================================\n",
        "from gtts import gTTS\n",
        "import whisper\n",
        "from phonikud import phonemize\n",
        "from IPython.display import Audio\n",
        "import os\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs(\"outputs/audio\", exist_ok=True)\n",
        "os.makedirs(\"outputs/transcripts\", exist_ok=True)\n",
        "\n",
        "# Initialize Whisper small model (fast)\n",
        "stt = whisper.load_model(\"small\")\n",
        "\n",
        "# =====================================\n",
        "# Step 3: Client text in Hebrew\n",
        "# =====================================\n",
        "client_text = \"שלום, אני רוצה לבטל את המנוי לטלוויזיה.\"\n",
        "\n",
        "# Phonemize (optional, for debugging)\n",
        "print(\"Client phonemes:\", phonemize(client_text))\n",
        "\n",
        "# Convert client text → audio\n",
        "client_audio_path = \"outputs/audio/client.wav\"\n",
        "gtts_client = gTTS(text=client_text, lang=\"iw\")\n",
        "gtts_client.save(client_audio_path)\n",
        "\n",
        "# Play client audio\n",
        "Audio(client_audio_path)\n",
        "\n",
        "# =====================================\n",
        "# Step 4: Transcribe client audio\n",
        "# =====================================\n",
        "result = stt.transcribe(client_audio_path, language=\"he\")\n",
        "transcript = result[\"text\"]\n",
        "\n",
        "# Save transcript\n",
        "with open(\"outputs/transcripts/client.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(transcript)\n",
        "\n",
        "print(\"Transcript:\", transcript)\n",
        "\n",
        "# =====================================\n",
        "# Step 5: Agent response\n",
        "# =====================================\n",
        "agent_response = \"שלום, אני מבין. אטפל בבקשת הביטול שלך.\"\n",
        "print(\"Agent phonemes:\", phonemize(agent_response))\n",
        "\n",
        "agent_audio_path = \"outputs/audio/agent.wav\"\n",
        "gtts_agent = gTTS(text=agent_response, lang=\"iw\")\n",
        "gtts_agent.save(agent_audio_path)\n",
        "\n",
        "# Save agent transcript\n",
        "with open(\"outputs/transcripts/agent.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(agent_response)\n",
        "\n",
        "# Play agent audio\n",
        "Audio(agent_audio_path)\n",
        "\n",
        "# =====================================\n",
        "# Step 6: Done\n",
        "# =====================================\n",
        "print(\"Simulation complete!\")\n",
        "print(\"Files saved under outputs/audio and outputs/transcripts.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agbc9eZWJLv-",
        "outputId": "238b78cb-0633-43d8-9efe-2e9af0fa3ac4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: phonikud in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from gTTS) (2.32.4)\n",
            "Collecting click<8.2,>=7.1 (from gTTS)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: colorlog>=6.9.0 in /usr/local/lib/python3.12/dist-packages (from phonikud) (6.9.0)\n",
            "Requirement already satisfied: num2words>=0.5.14 in /usr/local/lib/python3.12/dist-packages (from phonikud) (0.5.14)\n",
            "Requirement already satisfied: regex>=2024.11.6 in /usr/local/lib/python3.12/dist-packages (from phonikud) (2024.11.6)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.12/dist-packages (from num2words>=0.5.14->phonikud) (0.6.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (2025.8.3)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=b7f77bce66fd50bf9db37ce3448ea46099a257440ee768c5325617a679549a53\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 18.7M/425M [03:10<2:39:00, 42.6kiB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: click, gTTS, openai-whisper\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "Successfully installed click-8.1.8 gTTS-2.5.4 openai-whisper-20250625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|                                               | 0.00/461M [00:00<?, ?iB/s]\u001b[A\n",
            "  1%|▎                                     | 3.80M/461M [00:00<00:12, 39.8MiB/s]\u001b[A\n",
            "  3%|█                                     | 12.5M/461M [00:00<00:06, 69.4MiB/s]\u001b[A\n",
            "  4%|█▌                                    | 19.1M/461M [00:00<00:08, 54.7MiB/s]\u001b[A\n",
            "  5%|██                                    | 25.2M/461M [00:00<00:07, 57.9MiB/s]\u001b[A\n",
            "  7%|██▋                                   | 32.4M/461M [00:00<00:07, 63.2MiB/s]\u001b[A\n",
            "  8%|███▏                                  | 38.6M/461M [00:00<00:07, 59.6MiB/s]\u001b[A\n",
            " 10%|███▋                                  | 44.4M/461M [00:00<00:08, 54.5MiB/s]\u001b[A\n",
            " 11%|████▏                                 | 50.8M/461M [00:00<00:07, 57.8MiB/s]\u001b[A\n",
            " 12%|████▋                                 | 56.5M/461M [00:01<00:12, 34.9MiB/s]\u001b[A\n",
            " 13%|█████                                 | 60.9M/461M [00:01<00:12, 32.8MiB/s]\u001b[A\n",
            " 14%|█████▎                                | 64.7M/461M [00:01<00:13, 31.7MiB/s]\u001b[A\n",
            " 15%|█████▊                                | 71.2M/461M [00:01<00:10, 38.7MiB/s]\u001b[A\n",
            " 16%|██████▏                               | 75.5M/461M [00:01<00:10, 39.4MiB/s]\u001b[A\n",
            " 17%|██████▌                               | 80.2M/461M [00:01<00:09, 41.6MiB/s]\u001b[A\n",
            " 18%|██████▉                               | 84.5M/461M [00:01<00:09, 41.9MiB/s]\u001b[A\n",
            " 19%|███████▎                              | 88.8M/461M [00:02<00:13, 29.2MiB/s]\u001b[A\n",
            " 20%|███████▋                              | 92.6M/461M [00:02<00:12, 31.5MiB/s]\u001b[A\n",
            " 21%|███████▉                              | 96.3M/461M [00:02<00:11, 33.1MiB/s]\u001b[A\n",
            " 22%|████████▋                              | 103M/461M [00:02<00:09, 41.7MiB/s]\u001b[A\n",
            " 23%|█████████                              | 107M/461M [00:02<00:09, 40.9MiB/s]\u001b[A\n",
            " 24%|█████████▌                             | 112M/461M [00:02<00:08, 42.0MiB/s]\u001b[A\n",
            " 26%|█████████▉                             | 118M/461M [00:02<00:07, 45.8MiB/s]\u001b[A\n",
            " 27%|██████████▎                            | 122M/461M [00:03<00:19, 17.9MiB/s]\u001b[A\n",
            " 28%|██████████▊                            | 127M/461M [00:03<00:15, 22.2MiB/s]\u001b[A\n",
            " 28%|███████████                            | 131M/461M [00:03<00:14, 24.3MiB/s]\u001b[A\n",
            " 30%|███████████▋                           | 139M/461M [00:03<00:09, 34.4MiB/s]\u001b[A\n",
            " 31%|████████████▎                          | 145M/461M [00:04<00:08, 40.4MiB/s]\u001b[A\n",
            " 33%|████████████▉                          | 152M/461M [00:04<00:06, 48.6MiB/s]\u001b[A\n",
            " 34%|█████████████▍                         | 159M/461M [00:04<00:05, 53.2MiB/s]\u001b[A\n",
            " 36%|█████████████▉                         | 165M/461M [00:04<00:07, 40.1MiB/s]\u001b[A\n",
            " 37%|██████████████▎                        | 170M/461M [00:04<00:07, 42.3MiB/s]\u001b[A\n",
            " 39%|███████████████▏                       | 179M/461M [00:04<00:05, 55.6MiB/s]\u001b[A\n",
            " 40%|███████████████▋                       | 186M/461M [00:05<00:08, 34.9MiB/s]\u001b[A\n",
            " 42%|████████████████▎                      | 193M/461M [00:05<00:06, 41.8MiB/s]\u001b[A\n",
            " 43%|████████████████▊                      | 199M/461M [00:05<00:05, 46.0MiB/s]\u001b[A\n",
            " 44%|█████████████████▎                     | 205M/461M [00:05<00:05, 46.6MiB/s]\u001b[A\n",
            " 46%|█████████████████▊                     | 210M/461M [00:05<00:07, 34.8MiB/s]\u001b[A\n",
            " 47%|██████████████████▏                    | 214M/461M [00:05<00:07, 36.5MiB/s]\u001b[A\n",
            " 47%|██████████████████▍                    | 219M/461M [00:05<00:06, 38.0MiB/s]\u001b[A\n",
            " 48%|██████████████████▊                    | 223M/461M [00:05<00:06, 37.5MiB/s]\u001b[A\n",
            " 49%|███████████████████▏                   | 227M/461M [00:06<00:06, 37.4MiB/s]\u001b[A\n",
            " 50%|███████████████████▋                   | 233M/461M [00:06<00:05, 42.6MiB/s]\u001b[A\n",
            " 52%|████████████████████▎                  | 240M/461M [00:06<00:04, 50.2MiB/s]\u001b[A\n",
            " 53%|████████████████████▊                  | 245M/461M [00:06<00:04, 53.5MiB/s]\u001b[A\n",
            " 54%|█████████████████████▏                 | 251M/461M [00:06<00:04, 48.1MiB/s]\u001b[A\n",
            " 56%|█████████████████████▊                 | 258M/461M [00:06<00:03, 55.8MiB/s]\u001b[A\n",
            " 57%|██████████████████████▎                | 264M/461M [00:06<00:04, 46.6MiB/s]\u001b[A\n",
            " 58%|██████████████████████▊                | 269M/461M [00:06<00:04, 46.4MiB/s]\u001b[A\n",
            " 60%|███████████████████████▎               | 276M/461M [00:07<00:03, 52.2MiB/s]\u001b[A\n",
            " 61%|███████████████████████▊               | 281M/461M [00:07<00:03, 53.4MiB/s]\u001b[A\n",
            " 62%|████████████████████████▎              | 287M/461M [00:07<00:03, 51.9MiB/s]\u001b[A\n",
            " 63%|████████████████████████▋              | 292M/461M [00:07<00:03, 51.4MiB/s]\u001b[A\n",
            " 65%|█████████████████████████▏             | 299M/461M [00:07<00:03, 56.1MiB/s]\u001b[A\n",
            " 66%|█████████████████████████▋             | 304M/461M [00:07<00:02, 55.0MiB/s]\u001b[A\n",
            " 67%|██████████████████████████▎            | 311M/461M [00:07<00:02, 58.1MiB/s]\u001b[A\n",
            " 69%|██████████████████████████▋            | 316M/461M [00:07<00:02, 54.6MiB/s]\u001b[A\n",
            " 70%|███████████████████████████▎           | 323M/461M [00:07<00:02, 59.6MiB/s]\u001b[A\n",
            " 71%|███████████████████████████▊           | 329M/461M [00:08<00:04, 30.3MiB/s]\u001b[A\n",
            " 73%|████████████████████████████▎          | 335M/461M [00:08<00:03, 37.0MiB/s]\u001b[A\n",
            " 74%|████████████████████████████▊          | 341M/461M [00:08<00:04, 29.7MiB/s]\u001b[A\n",
            " 75%|█████████████████████████████▏         | 345M/461M [00:08<00:03, 32.3MiB/s]\u001b[A\n",
            " 76%|█████████████████████████████▋         | 352M/461M [00:08<00:02, 39.3MiB/s]\u001b[A\n",
            " 77%|██████████████████████████████▏        | 356M/461M [00:09<00:03, 29.2MiB/s]\u001b[A\n",
            " 78%|██████████████████████████████▍        | 360M/461M [00:09<00:03, 29.5MiB/s]\u001b[A\n",
            " 79%|██████████████████████████████▊        | 364M/461M [00:09<00:03, 29.1MiB/s]\u001b[A\n",
            " 80%|███████████████████████████████▏       | 369M/461M [00:09<00:02, 35.2MiB/s]\u001b[A\n",
            " 82%|███████████████████████████████▊       | 376M/461M [00:09<00:02, 43.3MiB/s]\u001b[A\n",
            " 83%|████████████████████████████████▍      | 384M/461M [00:09<00:01, 51.0MiB/s]\u001b[A\n",
            " 84%|████████████████████████████████▉      | 389M/461M [00:09<00:01, 48.6MiB/s]\u001b[A\n",
            " 85%|█████████████████████████████████▎     | 394M/461M [00:10<00:03, 22.1MiB/s]\u001b[A\n",
            " 87%|█████████████████████████████████▉     | 401M/461M [00:10<00:02, 28.7MiB/s]\u001b[A\n",
            " 88%|██████████████████████████████████▎    | 406M/461M [00:10<00:01, 32.3MiB/s]\u001b[A\n",
            " 89%|██████████████████████████████████▋    | 410M/461M [00:10<00:01, 35.1MiB/s]\u001b[A\n",
            " 90%|███████████████████████████████████    | 415M/461M [00:10<00:01, 37.5MiB/s]\u001b[A\n",
            " 91%|███████████████████████████████████▍   | 420M/461M [00:11<00:01, 27.1MiB/s]\u001b[A\n",
            " 92%|███████████████████████████████████▉   | 425M/461M [00:11<00:01, 32.4MiB/s]\u001b[A\n",
            " 94%|████████████████████████████████████▌  | 432M/461M [00:11<00:00, 41.1MiB/s]\u001b[A\n",
            " 95%|█████████████████████████████████████▏ | 440M/461M [00:11<00:00, 50.4MiB/s]\u001b[A\n",
            " 97%|█████████████████████████████████████▉ | 449M/461M [00:11<00:00, 59.2MiB/s]\u001b[A\n",
            "100%|███████████████████████████████████████| 461M/461M [00:11<00:00, 40.9MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client phonemes: ʃˈlm, ʔˈnj ʁˈts lˈvtl ʔˈt hˈmnj ltlvˈuz.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript:  שלום, אני רוצה לבטל את המנוי לטלוויזיה\n",
            "Agent phonemes: ʃˈlm, ʔˈnj mˈvn. ʔˈtfl vˈvkʃt hˈvtl ʃˈlχ.\n",
            "Simulation complete!\n",
            "Files saved under outputs/audio and outputs/transcripts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"outputs/audio/client.wav\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0pPw_HtaJrR5",
        "outputId": "88c93255-ce13-410a-de0c-add670bcdf0e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_921681b5-1d21-41e3-b207-0f5f2d696b88\", \"client.wav\", 32256)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"outputs/audio/agent.wav\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "DN-t5VA_J-o9",
        "outputId": "0c720920-6c2f-4ea7-8c7f-68228b9cd1b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_85f5c542-def1-494e-8019-a4ac2455be3f\", \"agent.wav\", 36672)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"outputs/transcripts/client.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Z3y9wK6CKBSP",
        "outputId": "7a9dd7ee-2082-4a27-e118-e351a4737ee5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_13286ff2-a039-4dad-88b5-7346b025b43b\", \"client.txt\", 70)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"outputs/transcripts/agent.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qm4qWas_KDET",
        "outputId": "91cb4ec2-7fa2-4b9f-95d9-946093d078db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4d8d9704-d4ba-4097-9f34-fb18eb119b59\", \"agent.txt\", 67)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}